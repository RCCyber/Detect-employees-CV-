{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "detect_employees.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN70VqonmVrIdlXImJzS10L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RCCyber/RCCyber/blob/main/detect_employees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WxeZWVjtXb93"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "\n",
        "from keras import backend as K\n",
        "K.image_dim_ordering='th'\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/sample_data/ && unzip data.zip"
      ],
      "metadata": {
        "id": "InPsPWvHF33I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inc_model=InceptionV3(include_top=False, \n",
        "                      weights='imagenet', \n",
        "                      input_shape=((116, 116, 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqubAErMX6Y4",
        "outputId": "7b10406b-1b28-46f9-adde-99ac0472938e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_datagen = ImageDataGenerator(rescale=1./255)  #собственно, генератор\n",
        "    \n",
        "train_generator = bottleneck_datagen.flow_from_directory('/content/sample_data/data/train/',\n",
        "                                        target_size=(116, 116),\n",
        "                                        batch_size=32,\n",
        "                                        class_mode=None,\n",
        "                                        shuffle=False)\n",
        "\n",
        "validation_generator = bottleneck_datagen.flow_from_directory('/content/sample_data/data/validation/', \n",
        "                                                              target_size=(116, 116),\n",
        "                                                               batch_size=32,\n",
        "                                                               class_mode=None,\n",
        "                                                               shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECLPig0PX6t_",
        "outputId": "99e0a98a-f3d1-49c9-e120-33f9f26a7119"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_features_train = inc_model.predict(train_generator, 2000)\n",
        "np.save(open('bn_features_train.npy', 'wb'), bottleneck_features_train)\n",
        "\n",
        "bottleneck_features_validation = inc_model.predict(validation_generator, 2000)\n",
        "np.save(open('bn_features_validation.npy', 'wb'), bottleneck_features_validation)"
      ],
      "metadata": {
        "id": "WS_-v6IyX62A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.load(open('bn_features_train.npy', 'rb'))\n",
        "train_labels = np.array([0] * 1000 + [1] * 1000) \n",
        "\n",
        "validation_data = np.load(open('bn_features_validation.npy', 'rb'))\n",
        "validation_labels = np.array([0] * 1000 + [1] * 1000)"
      ],
      "metadata": {
        "id": "cK9h69B7X67z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc_model = Sequential()\n",
        "fc_model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "fc_model.add(Dense(64, activation='relu', name='dense_one'))\n",
        "fc_model.add(Dropout(0.5, name='dropout_one'))\n",
        "fc_model.add(Dense(64, activation='relu', name='dense_two'))\n",
        "fc_model.add(Dropout(0.5, name='dropout_two'))\n",
        "fc_model.add(Dense(1, activation='sigmoid', name='output'))\n",
        "\n",
        "fc_model.compile(optimizer='rmsprop', \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BgCGAA4ZX6-V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#validation_labels = validation_labels.reshape(1, -1)\n",
        "#train_labels = train_labels.reshape(1, -1)\n",
        "print(validation_data.shape)\n",
        "print(validation_labels.shape)\n",
        "print(train_data.shape)\n",
        "print(train_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlXBESYgc81S",
        "outputId": "902b51aa-d312-4efc-b19c-4c23b472d5d1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000, 2, 2, 2048)\n",
            "(2000,)\n",
            "(2000, 2, 2, 2048)\n",
            "(2000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc_model.fit(train_data, train_labels, epochs=50, batch_size=32, validation_data=(validation_data, validation_labels))\n",
        "fc_model.save_weights('fc_inception_cats_dogs_250.hdf5') # сохраняем веса"
      ],
      "metadata": {
        "id": "iyI0kl9PX7FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc_model.evaluate(validation_data, validation_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHy5i4juVQ_x",
        "outputId": "9a2a3e02-92b1-4cfc-c301-f8d72019bf3a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 4ms/step - loss: 1.3855 - accuracy: 0.9315\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3854981660842896, 0.9315000176429749]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_filename='fc_inception_cats_dogs_250.hdf5'\n",
        "x = Flatten()(inc_model.output)\n",
        "x = Dense(64, activation='relu', name='dense_one')(x)\n",
        "x = Dropout(0.5, name='dropout_one')(x)\n",
        "x = Dense(64, activation='relu', name='dense_two')(x)\n",
        "x = Dropout(0.5, name='dropout_two')(x)\n",
        "top_model=Dense(1, activation='sigmoid', name='output')(x)\n",
        "model = Model(inputs=inc_model.input, outputs=top_model)"
      ],
      "metadata": {
        "id": "VqFDwhcONz7p"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_filename='fc_inception_cats_dogs_250.hdf5'\n",
        "model.load_weights(weights_filename, by_name=True)"
      ],
      "metadata": {
        "id": "jDuUMoAiN0FR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in inc_model.layers[:205]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "fvKoYSlnN0II"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=SGD(learning_rate=1e-4, momentum=0.9),\n",
        "                #optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yIyuGZG-N0Kv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "rF1ZqdstN0Nc"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255)#,\n",
        "        #shear_range=0.2,\n",
        "        #zoom_range=0.2,\n",
        "        #horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/sample_data/data/train/',\n",
        "        target_size=(116, 116),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/sample_data/data/validation/',\n",
        "        target_size=(116, 116),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "\n",
        "pred_generator=test_datagen.flow_from_directory('/content/sample_data/data/validation/',\n",
        "                                                     target_size=(116,116),\n",
        "                                                     batch_size=100,\n",
        "                                                     class_mode='binary')"
      ],
      "metadata": {
        "id": "SJ_CD3SoN0Py",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d1a59b0-9bcf-4c56-97ef-88951ddcaf5a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=2000,\n",
        "        epochs=200,\n",
        "        validation_data=validation_generator,\n",
        "        #nb_val_samples=2000,\n",
        "    callbacks=callbacks_list)"
      ],
      "metadata": {
        "id": "syPe5-ulN0Sf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "f252e9c3-c8f4-4d28-8ab0-7ad82d939de5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "  62/2000 [..............................] - ETA: 1:30 - loss: 0.0403 - accuracy: 0.9909WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 400000 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-62dcc1276b55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#nb_val_samples=2000,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     callbacks=callbacks_list)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_get_file_path\u001b[0;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m       raise KeyError(\n\u001b[0;32m-> 1487\u001b[0;31m           \u001b[0;34mf'Failed to format this callback filepath: \"{self.filepath}\". '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1488\u001b[0m           f'Reason: {e}')\n\u001b[1;32m   1489\u001b[0m     self._write_filepath = distributed_file_utils.write_filepath(\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Failed to format this callback filepath: \"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\". Reason: \\'val_acc\\''"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate_generator(pred_generator, val_samples=100)"
      ],
      "metadata": {
        "id": "mHjfhuqCOF4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mgs,labels=pred_generator.next()\n",
        "array_imgs=np.transpose(np.asarray([img_to_array(img) for img in imgs]),(0,2,1,3))\n",
        "predictions=model.predict(imgs)\n",
        "rounded_pred=np.asarray([round(i) for i in predictions])"
      ],
      "metadata": {
        "id": "BSnfFp9mOF73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong=[im for im in zip(array_imgs, rounded_pred, labels, predictions) if im[1]!=im[2]]\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "for ind, val in enumerate(wrong[:100]):\n",
        "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1, wspace = 0.2, hspace = 0.2)\n",
        "    plt.subplot(5,5,ind+1)\n",
        "    im=val[0]\n",
        "    plt.axis('off')\n",
        "    plt.text(120, 0, round(val[3], 2), fontsize=11, color='red')\n",
        "    plt.text(0, 0, val[2], fontsize=11, color='blue')\n",
        "    plt.imshow(np.transpose(im,(2,1,0)))"
      ],
      "metadata": {
        "id": "5UynCNIgOF-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "right=[im for im in zip(array_imgs, rounded_pred, labels, predictions) if im[1]==im[2]]\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "for ind, val in enumerate(right[:20]):\n",
        "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1, wspace = 0.2, hspace = 0.2)\n",
        "    plt.subplot(5,5,ind+1)\n",
        "    im=val[0]\n",
        "    plt.axis('off')\n",
        "    plt.text(120, 0, round(val[3], 2), fontsize=11, color='red')\n",
        "    plt.text(0, 0, val[2], fontsize=11, color='blue')\n",
        "    plt.imshow(np.transpose(im,(2,1,0)))"
      ],
      "metadata": {
        "id": "qSwOivOXOR30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WcfEhRfoOR6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8CyvG3cBOR9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DD2K9UJ2OR_1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}